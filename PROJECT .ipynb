{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Admission_Predict_Ver1.1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>330</td>\n",
       "      <td>115</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.34</td>\n",
       "      <td>1</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>321</td>\n",
       "      <td>109</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.20</td>\n",
       "      <td>1</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>308</td>\n",
       "      <td>101</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.90</td>\n",
       "      <td>0</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>302</td>\n",
       "      <td>102</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>323</td>\n",
       "      <td>108</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.60</td>\n",
       "      <td>0</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>325</td>\n",
       "      <td>106</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.40</td>\n",
       "      <td>1</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>327</td>\n",
       "      <td>111</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>328</td>\n",
       "      <td>112</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>307</td>\n",
       "      <td>109</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>311</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.20</td>\n",
       "      <td>1</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>314</td>\n",
       "      <td>105</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.30</td>\n",
       "      <td>0</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>317</td>\n",
       "      <td>107</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.70</td>\n",
       "      <td>0</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>319</td>\n",
       "      <td>106</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>318</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.80</td>\n",
       "      <td>0</td>\n",
       "      <td>0.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>303</td>\n",
       "      <td>102</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>312</td>\n",
       "      <td>107</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.90</td>\n",
       "      <td>1</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>325</td>\n",
       "      <td>114</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.40</td>\n",
       "      <td>0</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>328</td>\n",
       "      <td>116</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.50</td>\n",
       "      <td>1</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>334</td>\n",
       "      <td>119</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.70</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>336</td>\n",
       "      <td>119</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.80</td>\n",
       "      <td>1</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>340</td>\n",
       "      <td>120</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.60</td>\n",
       "      <td>1</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>322</td>\n",
       "      <td>109</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.80</td>\n",
       "      <td>0</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>298</td>\n",
       "      <td>98</td>\n",
       "      <td>2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>7.50</td>\n",
       "      <td>1</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>295</td>\n",
       "      <td>93</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.20</td>\n",
       "      <td>0</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>310</td>\n",
       "      <td>99</td>\n",
       "      <td>2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.30</td>\n",
       "      <td>0</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>471</td>\n",
       "      <td>320</td>\n",
       "      <td>110</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.27</td>\n",
       "      <td>1</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>472</td>\n",
       "      <td>311</td>\n",
       "      <td>103</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.09</td>\n",
       "      <td>0</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>473</td>\n",
       "      <td>327</td>\n",
       "      <td>116</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.48</td>\n",
       "      <td>1</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>474</td>\n",
       "      <td>316</td>\n",
       "      <td>102</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.15</td>\n",
       "      <td>0</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>475</td>\n",
       "      <td>308</td>\n",
       "      <td>105</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>7.95</td>\n",
       "      <td>1</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>476</td>\n",
       "      <td>300</td>\n",
       "      <td>101</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>7.88</td>\n",
       "      <td>0</td>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>477</td>\n",
       "      <td>304</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>478</td>\n",
       "      <td>309</td>\n",
       "      <td>105</td>\n",
       "      <td>4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>479</td>\n",
       "      <td>318</td>\n",
       "      <td>103</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.49</td>\n",
       "      <td>1</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>480</td>\n",
       "      <td>325</td>\n",
       "      <td>110</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.96</td>\n",
       "      <td>1</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>481</td>\n",
       "      <td>321</td>\n",
       "      <td>102</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>482</td>\n",
       "      <td>323</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.48</td>\n",
       "      <td>1</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>483</td>\n",
       "      <td>328</td>\n",
       "      <td>113</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.77</td>\n",
       "      <td>1</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>484</td>\n",
       "      <td>304</td>\n",
       "      <td>103</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.92</td>\n",
       "      <td>0</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>485</td>\n",
       "      <td>317</td>\n",
       "      <td>106</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.89</td>\n",
       "      <td>1</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>486</td>\n",
       "      <td>311</td>\n",
       "      <td>101</td>\n",
       "      <td>2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.34</td>\n",
       "      <td>1</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>487</td>\n",
       "      <td>319</td>\n",
       "      <td>102</td>\n",
       "      <td>3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.37</td>\n",
       "      <td>0</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>488</td>\n",
       "      <td>327</td>\n",
       "      <td>115</td>\n",
       "      <td>4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.14</td>\n",
       "      <td>0</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>489</td>\n",
       "      <td>322</td>\n",
       "      <td>112</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.62</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>490</td>\n",
       "      <td>302</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>491</td>\n",
       "      <td>307</td>\n",
       "      <td>105</td>\n",
       "      <td>2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>492</td>\n",
       "      <td>297</td>\n",
       "      <td>99</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>7.81</td>\n",
       "      <td>0</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>493</td>\n",
       "      <td>298</td>\n",
       "      <td>101</td>\n",
       "      <td>4</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>7.69</td>\n",
       "      <td>1</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>494</td>\n",
       "      <td>300</td>\n",
       "      <td>95</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>8.22</td>\n",
       "      <td>1</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>495</td>\n",
       "      <td>301</td>\n",
       "      <td>99</td>\n",
       "      <td>3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.45</td>\n",
       "      <td>1</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>496</td>\n",
       "      <td>332</td>\n",
       "      <td>108</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.02</td>\n",
       "      <td>1</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>497</td>\n",
       "      <td>337</td>\n",
       "      <td>117</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>498</td>\n",
       "      <td>330</td>\n",
       "      <td>120</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.56</td>\n",
       "      <td>1</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>499</td>\n",
       "      <td>312</td>\n",
       "      <td>103</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.43</td>\n",
       "      <td>0</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>500</td>\n",
       "      <td>327</td>\n",
       "      <td>113</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.04</td>\n",
       "      <td>0</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
       "0             1        337          118                  4  4.5   4.5  9.65   \n",
       "1             2        324          107                  4  4.0   4.5  8.87   \n",
       "2             3        316          104                  3  3.0   3.5  8.00   \n",
       "3             4        322          110                  3  3.5   2.5  8.67   \n",
       "4             5        314          103                  2  2.0   3.0  8.21   \n",
       "5             6        330          115                  5  4.5   3.0  9.34   \n",
       "6             7        321          109                  3  3.0   4.0  8.20   \n",
       "7             8        308          101                  2  3.0   4.0  7.90   \n",
       "8             9        302          102                  1  2.0   1.5  8.00   \n",
       "9            10        323          108                  3  3.5   3.0  8.60   \n",
       "10           11        325          106                  3  3.5   4.0  8.40   \n",
       "11           12        327          111                  4  4.0   4.5  9.00   \n",
       "12           13        328          112                  4  4.0   4.5  9.10   \n",
       "13           14        307          109                  3  4.0   3.0  8.00   \n",
       "14           15        311          104                  3  3.5   2.0  8.20   \n",
       "15           16        314          105                  3  3.5   2.5  8.30   \n",
       "16           17        317          107                  3  4.0   3.0  8.70   \n",
       "17           18        319          106                  3  4.0   3.0  8.00   \n",
       "18           19        318          110                  3  4.0   3.0  8.80   \n",
       "19           20        303          102                  3  3.5   3.0  8.50   \n",
       "20           21        312          107                  3  3.0   2.0  7.90   \n",
       "21           22        325          114                  4  3.0   2.0  8.40   \n",
       "22           23        328          116                  5  5.0   5.0  9.50   \n",
       "23           24        334          119                  5  5.0   4.5  9.70   \n",
       "24           25        336          119                  5  4.0   3.5  9.80   \n",
       "25           26        340          120                  5  4.5   4.5  9.60   \n",
       "26           27        322          109                  5  4.5   3.5  8.80   \n",
       "27           28        298           98                  2  1.5   2.5  7.50   \n",
       "28           29        295           93                  1  2.0   2.0  7.20   \n",
       "29           30        310           99                  2  1.5   2.0  7.30   \n",
       "..          ...        ...          ...                ...  ...   ...   ...   \n",
       "470         471        320          110                  5  4.0   4.0  9.27   \n",
       "471         472        311          103                  3  2.0   4.0  8.09   \n",
       "472         473        327          116                  4  4.0   4.5  9.48   \n",
       "473         474        316          102                  2  4.0   3.5  8.15   \n",
       "474         475        308          105                  4  3.0   2.5  7.95   \n",
       "475         476        300          101                  3  3.5   2.5  7.88   \n",
       "476         477        304          104                  3  2.5   2.0  8.12   \n",
       "477         478        309          105                  4  3.5   2.0  8.18   \n",
       "478         479        318          103                  3  4.0   4.5  8.49   \n",
       "479         480        325          110                  4  4.5   4.0  8.96   \n",
       "480         481        321          102                  3  3.5   4.0  9.01   \n",
       "481         482        323          107                  4  3.0   2.5  8.48   \n",
       "482         483        328          113                  4  4.0   2.5  8.77   \n",
       "483         484        304          103                  5  5.0   3.0  7.92   \n",
       "484         485        317          106                  3  3.5   3.0  7.89   \n",
       "485         486        311          101                  2  2.5   3.5  8.34   \n",
       "486         487        319          102                  3  2.5   2.5  8.37   \n",
       "487         488        327          115                  4  3.5   4.0  9.14   \n",
       "488         489        322          112                  3  3.0   4.0  8.62   \n",
       "489         490        302          110                  3  4.0   4.5  8.50   \n",
       "490         491        307          105                  2  2.5   4.5  8.12   \n",
       "491         492        297           99                  4  3.0   3.5  7.81   \n",
       "492         493        298          101                  4  2.5   4.5  7.69   \n",
       "493         494        300           95                  2  3.0   1.5  8.22   \n",
       "494         495        301           99                  3  2.5   2.0  8.45   \n",
       "495         496        332          108                  5  4.5   4.0  9.02   \n",
       "496         497        337          117                  5  5.0   5.0  9.87   \n",
       "497         498        330          120                  5  4.5   5.0  9.56   \n",
       "498         499        312          103                  4  4.0   5.0  8.43   \n",
       "499         500        327          113                  4  4.5   4.5  9.04   \n",
       "\n",
       "     Research  Chance of Admit   \n",
       "0           1              0.92  \n",
       "1           1              0.76  \n",
       "2           1              0.72  \n",
       "3           1              0.80  \n",
       "4           0              0.65  \n",
       "5           1              0.90  \n",
       "6           1              0.75  \n",
       "7           0              0.68  \n",
       "8           0              0.50  \n",
       "9           0              0.45  \n",
       "10          1              0.52  \n",
       "11          1              0.84  \n",
       "12          1              0.78  \n",
       "13          1              0.62  \n",
       "14          1              0.61  \n",
       "15          0              0.54  \n",
       "16          0              0.66  \n",
       "17          1              0.65  \n",
       "18          0              0.63  \n",
       "19          0              0.62  \n",
       "20          1              0.64  \n",
       "21          0              0.70  \n",
       "22          1              0.94  \n",
       "23          1              0.95  \n",
       "24          1              0.97  \n",
       "25          1              0.94  \n",
       "26          0              0.76  \n",
       "27          1              0.44  \n",
       "28          0              0.46  \n",
       "29          0              0.54  \n",
       "..        ...               ...  \n",
       "470         1              0.87  \n",
       "471         0              0.64  \n",
       "472         1              0.90  \n",
       "473         0              0.67  \n",
       "474         1              0.67  \n",
       "475         0              0.59  \n",
       "476         0              0.62  \n",
       "477         0              0.65  \n",
       "478         1              0.71  \n",
       "479         1              0.79  \n",
       "480         1              0.80  \n",
       "481         1              0.78  \n",
       "482         1              0.83  \n",
       "483         0              0.71  \n",
       "484         1              0.73  \n",
       "485         1              0.70  \n",
       "486         0              0.68  \n",
       "487         0              0.79  \n",
       "488         1              0.76  \n",
       "489         0              0.65  \n",
       "490         1              0.67  \n",
       "491         0              0.54  \n",
       "492         1              0.53  \n",
       "493         1              0.62  \n",
       "494         1              0.68  \n",
       "495         1              0.87  \n",
       "496         1              0.96  \n",
       "497         1              0.93  \n",
       "498         0              0.73  \n",
       "499         0              0.84  \n",
       "\n",
       "[500 rows x 9 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=df.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.  , 337.  , 118.  , ...,   9.65,   1.  ,   0.92],\n",
       "       [  2.  , 324.  , 107.  , ...,   8.87,   1.  ,   0.76],\n",
       "       [  3.  , 316.  , 104.  , ...,   8.  ,   1.  ,   0.72],\n",
       "       ...,\n",
       "       [498.  , 330.  , 120.  , ...,   9.56,   1.  ,   0.93],\n",
       "       [499.  , 312.  , 103.  , ...,   8.43,   0.  ,   0.73],\n",
       "       [500.  , 327.  , 113.  , ...,   9.04,   0.  ,   0.84]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_data=df.copy()\n",
    "data=dataset[:,1:8]\n",
    "labels=dataset[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=data[:400]\n",
    "test_data=data[400:]\n",
    "train_labels=labels[:400]\n",
    "test_labels=labels[400:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NORMALIZE THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = train_data.mean(axis = 0)\n",
    "train_data -= mean\n",
    "std = train_data.std(axis = 0)\n",
    "train_data /=std\n",
    "test_data -= mean\n",
    "test_data /= std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(35, activation = 'sigmoid',input_shape = (train_data.shape[1],)))\n",
    "model.add(layers.Dense(14, activation = 'sigmoid'))\n",
    "model.add(layers.Dense(9, activation = \"sigmoid\"))\n",
    "model.add(layers.Dense(1))\n",
    "model.compile(optimizer='rmsprop',loss='mse',metrics=['mae'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Student.DESKTOP-3HHPE68\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/100\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 1.6548 - mean_absolute_error: 1.2785\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.3138 - mean_absolute_error: 1.1386\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.0972 - mean_absolute_error: 1.0396\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.9254 - mean_absolute_error: 0.9537\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.7810 - mean_absolute_error: 0.8750\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6565 - mean_absolute_error: 0.8010\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5483 - mean_absolute_error: 0.7305\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4540 - mean_absolute_error: 0.6630\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3720 - mean_absolute_error: 0.5982\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3011 - mean_absolute_error: 0.5360\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2403 - mean_absolute_error: 0.4763\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1888 - mean_absolute_error: 0.4191\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1458 - mean_absolute_error: 0.3645\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1103 - mean_absolute_error: 0.3129\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0818 - mean_absolute_error: 0.2654\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0593 - mean_absolute_error: 0.2222\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0423 - mean_absolute_error: 0.1847\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0298 - mean_absolute_error: 0.1526\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0212 - mean_absolute_error: 0.1262\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0157 - mean_absolute_error: 0.1059\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0134 - mean_absolute_error: 0.096 - 0s 3ms/step - loss: 0.0124 - mean_absolute_error: 0.0916\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0106 - mean_absolute_error: 0.0824\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0096 - mean_absolute_error: 0.0769\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0090 - mean_absolute_error: 0.0734\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0085 - mean_absolute_error: 0.0708\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0080 - mean_absolute_error: 0.0687\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0076 - mean_absolute_error: 0.0666\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0072 - mean_absolute_error: 0.0647\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0069 - mean_absolute_error: 0.0630\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0065 - mean_absolute_error: 0.0616\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0063 - mean_absolute_error: 0.0605\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0061 - mean_absolute_error: 0.0597\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0059 - mean_absolute_error: 0.0590\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0058 - mean_absolute_error: 0.0584\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0056 - mean_absolute_error: 0.0576\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0057 - mean_absolute_error: 0.0581\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0055 - mean_absolute_error: 0.0564\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0054 - mean_absolute_error: 0.0561\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0053 - mean_absolute_error: 0.0554\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0053 - mean_absolute_error: 0.0558\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0052 - mean_absolute_error: 0.0545\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0051 - mean_absolute_error: 0.0547\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0051 - mean_absolute_error: 0.0538\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0050 - mean_absolute_error: 0.0537\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0050 - mean_absolute_error: 0.0530\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0049 - mean_absolute_error: 0.0531\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0049 - mean_absolute_error: 0.0522\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0048 - mean_absolute_error: 0.0525\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0048 - mean_absolute_error: 0.0515\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0047 - mean_absolute_error: 0.0518\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0047 - mean_absolute_error: 0.0509\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0047 - mean_absolute_error: 0.0512\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0046 - mean_absolute_error: 0.0504\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0046 - mean_absolute_error: 0.0507\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0046 - mean_absolute_error: 0.0499\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0046 - mean_absolute_error: 0.0502\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0045 - mean_absolute_error: 0.0495\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0045 - mean_absolute_error: 0.0498\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0045 - mean_absolute_error: 0.0491\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0045 - mean_absolute_error: 0.0495\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0045 - mean_absolute_error: 0.0488\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0044 - mean_absolute_error: 0.0492\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0044 - mean_absolute_error: 0.0486\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0044 - mean_absolute_error: 0.0490\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0044 - mean_absolute_error: 0.0483\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0044 - mean_absolute_error: 0.0488\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0044 - mean_absolute_error: 0.0481\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0044 - mean_absolute_error: 0.0486\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0044 - mean_absolute_error: 0.0480\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0043 - mean_absolute_error: 0.0485\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0043 - mean_absolute_error: 0.0478\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0043 - mean_absolute_error: 0.0483\n",
      "Epoch 73/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0043 - mean_absolute_error: 0.0477\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0043 - mean_absolute_error: 0.0482\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0043 - mean_absolute_error: 0.0476\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0043 - mean_absolute_error: 0.0481\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0043 - mean_absolute_error: 0.0475\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0043 - mean_absolute_error: 0.0480\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0043 - mean_absolute_error: 0.0474\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0043 - mean_absolute_error: 0.0479\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0043 - mean_absolute_error: 0.0473\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0043 - mean_absolute_error: 0.0479\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0043 - mean_absolute_error: 0.0472\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0043 - mean_absolute_error: 0.0478\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0042 - mean_absolute_error: 0.0471\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0042 - mean_absolute_error: 0.0477\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0042 - mean_absolute_error: 0.0471\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0042 - mean_absolute_error: 0.0477\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0042 - mean_absolute_error: 0.0470\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0042 - mean_absolute_error: 0.0476\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0042 - mean_absolute_error: 0.0470\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0042 - mean_absolute_error: 0.0475\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0042 - mean_absolute_error: 0.0469\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0042 - mean_absolute_error: 0.0475\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0042 - mean_absolute_error: 0.0468\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0042 - mean_absolute_error: 0.0474\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0042 - mean_absolute_error: 0.0468\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0042 - mean_absolute_error: 0.0474\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0042 - mean_absolute_error: 0.0467\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0042 - mean_absolute_error: 0.0473\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x17c8dc4bcc0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_data, train_labels, epochs=100, batch_size=1, verbose=1,steps_per_epoch=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 40us/sample - loss: 0.0021 - mean_absolute_error: 0.0361\n",
      "test_acc: 0.03611078\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_data, test_labels)\n",
    "print('test_acc:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
